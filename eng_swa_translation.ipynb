{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "_cANujOYQmpU",
        "outputId": "4d30e725-1828-447a-fee9-11e45c8ea729"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'cpu'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import math\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchtext import transforms\n",
        "import numpy as np\n",
        "import pathlib\n",
        "import tqdm\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kmd5LsZwtFzF",
        "outputId": "bb822d47-47f2-4799-b5fa-7a94e2e6a3eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_pNBWSARJzD",
        "outputId": "ea6c4d4b-5302-4777-db1e-39b23de4bc1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Size of swahili dataset: 5000 \n",
            "Size of english dataset: 5000 \n",
            "Max swahili sentence: 249 \n",
            "Max english sentence: 233 \n",
            "['Huyo ni rafiki yako mpya?', 'Job hana hamu ya mpira wa vikapu.', 'Adam aliniambia kuwa Alice alikuwa na mpenzi mpya wa kiume', 'Radio haikutanga kuhusu ajali hiyo.', 'Adamu ana wasiwasi tutapotea.']\n",
            "['Is that your new friend?', \"Jacob wasn't interested in baseball.\", 'Adam told me that Alice had a new boyfriend.', \"The radio didn't inform about the accident.\", \"Adam is worried we'll get lost.\"]\n",
            "Eng vocab: ['', '°', '’', 'w', 'a', 'x', 's', 'I', \"'\", 'E', 'i', 'Z', 'S', '\"', 'O', 'T', 'j', 'C', '!', 'H', '7', 'g', 'P', 'u', 'v', '3', 'N', ',', 'z', '8', 'm', 'A', '?', '5', 'K', '1', 'c', 'M', 'k', '(', 'é', 'b', '”', 'V', 'o', 'l', 'J', '$', '&', 'B', '4', 'Y', 'r', '“', '9', '0', 'e', 'à', '—', 'R', 'd', 'L', 'q', 'F', 'n', 'f', ')', 'G', ';', '2', 'W', '6', 'y', 'p', 't', ':', '-', '_', 'D', ' ', 'U', 'Q', '.', 'h', '', '', '']\n",
            "Swa vocab: ['', 'w', 'a', 'x', 's', 'I', \"'\", 'E', 'i', 'Z', 'S', '\"', 'O', 'T', 'j', 'C', '!', 'H', '7', 'g', 'P', 'u', 'v', '3', 'N', ',', 'z', '8', 'm', 'A', '?', '5', 'K', '1', 'c', 'M', 'k', '(', 'b', '”', 'V', 'o', 'l', 'J', '$', '&', 'B', '4', 'Y', 'r', '9', '0', 'e', '—', 'R', 'd', 'L', 'F', 'q', 'n', 'f', ')', '/', 'G', ';', '2', 'W', '+', '\\u200b', '6', 'y', 'p', 't', ':', '-', 'D', ' ', 'U', 'Q', '.', 'h', '', '']\n",
            "Eng vocab_size :83\n",
            "Swa vocab_size :87\n",
            "{'': 82, 'w': 1, 'a': 2, 'x': 3, 's': 4, 'I': 5, \"'\": 6, 'E': 7, 'i': 8, 'Z': 9, 'S': 10, '\"': 11, 'O': 12, 'T': 13, 'j': 14, 'C': 15, '!': 16, 'H': 17, '7': 18, 'g': 19, 'P': 20, 'u': 21, 'v': 22, '3': 23, 'N': 24, ',': 25, 'z': 26, '8': 27, 'm': 28, 'A': 29, '?': 30, '5': 31, 'K': 32, '1': 33, 'c': 34, 'M': 35, 'k': 36, '(': 37, 'b': 38, '”': 39, 'V': 40, 'o': 41, 'l': 42, 'J': 43, '$': 44, '&': 45, 'B': 46, '4': 47, 'Y': 48, 'r': 49, '9': 50, '0': 51, 'e': 52, '—': 53, 'R': 54, 'd': 55, 'L': 56, 'F': 57, 'q': 58, 'n': 59, 'f': 60, ')': 61, '/': 62, 'G': 63, ';': 64, '2': 65, 'W': 66, '+': 67, '\\u200b': 68, '6': 69, 'y': 70, 'p': 71, 't': 72, ':': 73, '-': 74, 'D': 75, ' ': 76, 'U': 77, 'Q': 78, '.': 79, 'h': 80}\n",
            "{'': 86, '°': 1, '’': 2, 'w': 3, 'a': 4, 'x': 5, 's': 6, 'I': 7, \"'\": 8, 'E': 9, 'i': 10, 'Z': 11, 'S': 12, '\"': 13, 'O': 14, 'T': 15, 'j': 16, 'C': 17, '!': 18, 'H': 19, '7': 20, 'g': 21, 'P': 22, 'u': 23, 'v': 24, '3': 25, 'N': 26, ',': 27, 'z': 28, '8': 29, 'm': 30, 'A': 31, '?': 32, '5': 33, 'K': 34, '1': 35, 'c': 36, 'M': 37, 'k': 38, '(': 39, 'é': 40, 'b': 41, '”': 42, 'V': 43, 'o': 44, 'l': 45, 'J': 46, '$': 47, '&': 48, 'B': 49, '4': 50, 'Y': 51, 'r': 52, '“': 53, '9': 54, '0': 55, 'e': 56, 'à': 57, '—': 58, 'R': 59, 'd': 60, 'L': 61, 'q': 62, 'F': 63, 'n': 64, 'f': 65, ')': 66, 'G': 67, ';': 68, '2': 69, 'W': 70, '6': 71, 'y': 72, 'p': 73, 't': 74, ':': 75, '-': 76, '_': 77, 'D': 78, ' ': 79, 'U': 80, 'Q': 81, '.': 82, 'h': 83}\n"
          ]
        }
      ],
      "source": [
        "# read in the data from files to lists of strings\n",
        "START_TOKEN = ''\n",
        "PADDING_TOKEN = ''\n",
        "END_TOKEN = ''\n",
        "\n",
        "swa_sentences = []\n",
        "with open(\"./dataset/gamayun_kit5k.swa\",\"r\") as f:\n",
        "    for s in f.readlines():\n",
        "      s = START_TOKEN + s.rstrip(\"\\n\") + END_TOKEN\n",
        "      swa_sentences.append(s)\n",
        "\n",
        "eng_sentences = []\n",
        "with open(\"./dataset/gamayun_kit5k.eng\",\"r\") as f:\n",
        "    for s in f.readlines():\n",
        "      s =  s.rstrip(\"\\n\")\n",
        "      eng_sentences.append(s)\n",
        "\n",
        "print(f\"Size of swahili dataset: {len(swa_sentences)} \")\n",
        "print(f\"Size of english dataset: {len(eng_sentences)} \")\n",
        "print(f\"Max swahili sentence: {max([len(s) for s in swa_sentences])} \")\n",
        "print(f\"Max english sentence: {max([len(s) for s in eng_sentences])} \")\n",
        "\n",
        "print(swa_sentences[:5])\n",
        "print(eng_sentences[:5])\n",
        "\n",
        "# prep swa vocab\n",
        "swa_vocab = list(set(''.join(swa_sentences)))\n",
        "swa_vocab.insert(0,START_TOKEN)\n",
        "swa_vocab.append(PADDING_TOKEN)\n",
        "swa_vocab.append(END_TOKEN)\n",
        "\n",
        "# prep eng vocab\n",
        "eng_vocab = list(set(''.join(eng_sentences)))\n",
        "eng_vocab.append(PADDING_TOKEN)\n",
        "eng_vocab.insert(0,START_TOKEN)\n",
        "eng_vocab.append(PADDING_TOKEN)\n",
        "eng_vocab.append(END_TOKEN)\n",
        "\n",
        "print(f\"Eng vocab: {eng_vocab}\")\n",
        "print(f\"Swa vocab: {swa_vocab}\")\n",
        "\n",
        "swa_vocab_size = len(swa_vocab)\n",
        "eng_vocab_size = len(eng_vocab)\n",
        "\n",
        "\n",
        "print(f\"Eng vocab_size :{len(swa_vocab)}\")\n",
        "print(f\"Swa vocab_size :{len(eng_vocab)}\")\n",
        "\n",
        "swa_token_to_index = {t:i for i,t in enumerate(swa_vocab)}\n",
        "print(swa_token_to_index)\n",
        "swa_index_to_token = {i:t for i,t in enumerate(swa_vocab)}\n",
        "# print(swa_index_to_token)\n",
        "eng_token_to_index = {t:i for i,t in enumerate(eng_vocab)}\n",
        "print(eng_token_to_index)\n",
        "eng_index_to_token = {i:t for i,t in enumerate(eng_vocab)}\n",
        "# print(eng_index_to_token)\n",
        "\n",
        "# tokenize\n",
        "swahili_sentences_tokenized = [[swa_token_to_index[t] for t in s] for s in swa_sentences]\n",
        "english_sentences_tokenized = [[eng_token_to_index[t] for t in s] for s in eng_sentences]\n",
        "\n",
        "# train/test split\n",
        "swahili_sentences_tokenized_train = swahili_sentences_tokenized[:4500]\n",
        "swahili_sentences_tokenized_test = swahili_sentences_tokenized[4500:]\n",
        "english_sentences_tokenized_train = english_sentences_tokenized[:4500]\n",
        "english_sentences_tokenized_test = english_sentences_tokenized[4500:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "WAwFlb0ETV4s"
      },
      "outputs": [],
      "source": [
        "NEG_INFTY = -1e10\n",
        "\n",
        "class TranslationDataset(Dataset):\n",
        "\n",
        "    def __init__(self, swahili_sentences, english_sentences, transforms=None, eng_max_sequence_length=260, swa_max_sequence_length=260):\n",
        "        self.english_sentences = english_sentences\n",
        "        self.swahili_sentences = swahili_sentences\n",
        "        self.transforms = transforms\n",
        "        self.eng_max_sequence_length = eng_max_sequence_length\n",
        "        self.swa_max_sequence_length = swa_max_sequence_length\n",
        "        self.encoder_padding_mask = torch.full([self.eng_max_sequence_length, self.eng_max_sequence_length] , False) # each sentence gets a mask\n",
        "        self.look_ahead_mask = torch.triu(torch.full([self.swa_max_sequence_length, self.swa_max_sequence_length] , True), diagonal=1)\n",
        "        self.decoder_padding_mask_self_attention = torch.full([self.swa_max_sequence_length, self.swa_max_sequence_length] , False) # each sentence gets a mask\n",
        "        self.decoder_padding_mask_cross_attention = torch.full([self.swa_max_sequence_length, self.eng_max_sequence_length] , False) # each sentence gets a mask\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.english_sentences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        eng_sentence = self.english_sentences[idx]\n",
        "        swa_sentence = self.swahili_sentences[idx]\n",
        "        eng_sentence_length = len(eng_sentence)\n",
        "        swa_sentence_length = len(swa_sentence)\n",
        "        eng_chars_to_padding_mask = np.arange(eng_sentence_length, self.eng_max_sequence_length) # fillers\n",
        "        swa_chars_to_padding_mask = np.arange(swa_sentence_length, self.swa_max_sequence_length) # fillers\n",
        "\n",
        "        for _ in range(len(eng_sentence), self.eng_max_sequence_length):\n",
        "            eng_sentence.append(eng_token_to_index[PADDING_TOKEN])\n",
        "        for _ in range(len(swa_sentence), self.swa_max_sequence_length):\n",
        "            swa_sentence.append(swa_token_to_index[PADDING_TOKEN])\n",
        "\n",
        "        self.encoder_padding_mask[:, eng_chars_to_padding_mask] = True\n",
        "        self.encoder_padding_mask[eng_chars_to_padding_mask, :] = True\n",
        "        encoder_padding_mask = torch.where(self.encoder_padding_mask, NEG_INFTY, 0) # encoder mask\n",
        "\n",
        "        self.decoder_padding_mask_self_attention[:, swa_chars_to_padding_mask] = True\n",
        "        self.decoder_padding_mask_self_attention[swa_chars_to_padding_mask, :] = True\n",
        "        decoder_self_attention_mask = torch.where(self.decoder_padding_mask_self_attention+self.look_ahead_mask, NEG_INFTY, 0) # decoder self-attention mask\n",
        "\n",
        "        self.decoder_padding_mask_cross_attention[:, eng_chars_to_padding_mask] = True\n",
        "        self.decoder_padding_mask_cross_attention[swa_chars_to_padding_mask, :] = True\n",
        "        decoder_cross_attention_mask = torch.where(self.decoder_padding_mask_cross_attention, NEG_INFTY, 0) # decoder cross-attention mask\n",
        "\n",
        "        if self.transforms:\n",
        "            swa_sentence = self.transforms(swa_sentence)\n",
        "            eng_sentence = self.transforms(eng_sentence)\n",
        "\n",
        "        return eng_sentence,encoder_padding_mask, swa_sentence, decoder_self_attention_mask, decoder_cross_attention_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "xwemWvADTftP"
      },
      "outputs": [],
      "source": [
        "class EmeddingsLayer(nn.Module):\n",
        "    def __init__(self, d_model:int, vocab_size: int):\n",
        "        super().__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.d_model = d_model\n",
        "        self.embedding = nn.Embedding(num_embeddings=self.vocab_size, embedding_dim=self.d_model)\n",
        "\n",
        "    def forward(self, X):\n",
        "        return self.embedding(X) * math.sqrt(self.d_model) # \"In the embedding layers, we multiply those weights by sqrt(d_model)\"\n",
        "\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model:int, context_size:int):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.context_size = context_size\n",
        "        # print(self.context_size)\n",
        "\n",
        "        self.pe = torch.zeros(self.context_size, self.d_model,requires_grad=False)\n",
        "        for pos in range(self.context_size):\n",
        "            for i in range(0, self.d_model, 2):\n",
        "                self.pe[pos, i] = math.sin(pos / (10000 ** ((2 * i)/self.d_model)))\n",
        "                self.pe[pos, i + 1] = math.cos(pos / (10000 ** ((2 * (i + 1))/self.d_model)))\n",
        "\n",
        "    def forward(self):\n",
        "        return self.pe.unsqueeze(0)\n",
        "\n",
        "\n",
        "# embed_test = EmeddingsLayer(d_model=512,vocab_size=50000)\n",
        "# pencoding = PositionalEncoding(d_model=512,context_size=1024)\n",
        "# example_data = torch.randint(1,50000,(64,1024))\n",
        "# print(example_data.shape)\n",
        "# embed_output = embed_test(example_data)\n",
        "# print(embed_output.shape,embed_output[0][0][:10])\n",
        "# pe_output = pencoding()\n",
        "# print(pe_output.shape,pe_output[0][0][:10])\n",
        "# embed_pos_output = embed_output + pe_output\n",
        "# print(embed_pos_output.shape,embed_pos_output[0][0][:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gviy0SfcUZwZ",
        "outputId": "8452afde-b795-4b34-9cf7-8f4fda79fa77"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([10, 250, 512])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class AttentionHead(nn.Module):\n",
        "\n",
        "    def __init__(self, head_dim:int,p_drop:float) -> None:\n",
        "        super().__init__()\n",
        "        self.queries= nn.Linear(in_features=head_dim,out_features=head_dim,device=device) # kaparthy set bias=False why?\n",
        "        self.keys = nn.Linear(in_features=head_dim,out_features=head_dim,device=device) # kaparthy set bias=False why?\n",
        "        self.values = nn.Linear(in_features=head_dim,out_features=head_dim,device=device) # kaparthy set bias=False why?\n",
        "        self.dropout = nn.Dropout(p=p_drop)\n",
        "\n",
        "    def forward(self,Q:torch.Tensor,K:torch.Tensor,V:torch.Tensor,mask:torch.Tensor = None) -> torch.Tensor:\n",
        "        B,T,C = K.shape\n",
        "        # print(Q.device)\n",
        "        Q = self.dropout(self.queries(Q))\n",
        "        K = self.dropout(self.keys(K))\n",
        "        V = self.dropout(self.values(V))\n",
        "        scaled_dot_product_attention = (Q @ K.transpose(2,1))/torch.sqrt(torch.tensor(C))\n",
        "        if mask is not None:\n",
        "            scaled_dot_product_attention = scaled_dot_product_attention + mask\n",
        "        dot_product_softened = torch.softmax(scaled_dot_product_attention,dim=-1)\n",
        "        return dot_product_softened @ V\n",
        "\n",
        "\n",
        "class MultiHeadSelfAttention(nn.Module):\n",
        "    def __init__(self,d_model:int, p_drop:float, num_heads:int = 8) -> None:\n",
        "        super().__init__()\n",
        "        self.head_dim = math.floor(d_model/num_heads)\n",
        "        self.layer_norm = nn.LayerNorm(d_model)\n",
        "        self.heads = [AttentionHead(head_dim=self.head_dim,p_drop=p_drop) for h in range(num_heads)]\n",
        "        self.linear = nn.Linear(d_model,d_model)\n",
        "        self.dropout = nn.Dropout(p=p_drop)\n",
        "\n",
        "    def forward(self,X:torch.Tensor,Q:tuple,K:tuple,V:tuple, mask:torch.Tensor = None) ->torch.Tensor:\n",
        "        heads_output = []\n",
        "        for head_index,head in enumerate(self.heads):\n",
        "            queries = Q[head_index]\n",
        "            keys = K[head_index]\n",
        "            values = V[head_index]\n",
        "            v = head(queries,keys,values,mask) # this could be distributed to multiple devices for // processing\n",
        "            heads_output.append(v) # accumulate result\n",
        "\n",
        "        o = torch.cat(heads_output,dim=-1) #concat\n",
        "        linear_output = self.linear(o) #linear\n",
        "        dropped_output = self.dropout(linear_output) #dropout\n",
        "        mhsa_output = self.layer_norm(X+dropped_output)\n",
        "        return mhsa_output\n",
        "\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self,d_model:int,p_drop:float,d_ff:int) -> None:\n",
        "        super().__init__()\n",
        "        self.ffn = nn.Sequential(\n",
        "            nn.Linear(in_features=d_model,out_features=d_ff),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=p_drop),\n",
        "            nn.Linear(in_features=d_ff,out_features=d_model)\n",
        "        )\n",
        "        self.layer_norm = nn.LayerNorm(d_model)\n",
        "\n",
        "    def forward(self,X:torch.Tensor) -> torch.Tensor:\n",
        "        return self.layer_norm(X+self.ffn(X))\n",
        "\n",
        "\n",
        "mhsa = MultiHeadSelfAttention(d_model=512,p_drop=0.1,num_heads=8).to(device)\n",
        "sample_data = torch.randn((10,250,512)).to(device)\n",
        "splits = torch.split(sample_data,64,dim=2)\n",
        "mhsa(sample_data,splits,splits,splits,mask=None).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "hmZCuauGTuU3"
      },
      "outputs": [],
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, d_model:int, p_drop:float, d_ff:int, num_heads:int, **kwargs) -> None:\n",
        "        super().__init__()\n",
        "        self.head_dim = d_model // num_heads\n",
        "        self.multihead_self_attention = MultiHeadSelfAttention(d_model=d_model,p_drop=p_drop,num_heads=num_heads)\n",
        "        self.feedforward = FeedForward(d_model=d_model,p_drop=p_drop,d_ff=d_ff)\n",
        "\n",
        "    def forward(self,X:torch.Tensor,mask:torch.Tensor=None) -> torch.Tensor:\n",
        "        splits = torch.split(X,self.head_dim,dim=2)\n",
        "        return self.feedforward(self.multihead_self_attention(X,splits,splits,splits,mask))\n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, number_of_encoder_blocks:int=6,**kwargs) -> None:\n",
        "        super().__init__()\n",
        "        self.encoders = nn.ModuleList([EncoderLayer(**kwargs) for n in range(number_of_encoder_blocks)])\n",
        "\n",
        "    def forward(self,X:torch.Tensor,mask:torch.Tensor=None) -> torch.Tensor:\n",
        "        outputs = X\n",
        "        for encoder_layer in self.encoders:\n",
        "            outputs = encoder_layer(outputs,mask)\n",
        "        return outputs\n",
        "\n",
        "\n",
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self,d_model:int,p_drop:float,d_ff:int,num_heads:int,**kwargs) -> None:\n",
        "        super().__init__()\n",
        "        self.head_dim = d_model // num_heads\n",
        "        self.masked_multi_head_self_attention = MultiHeadSelfAttention(d_model=d_model,p_drop=p_drop,num_heads=num_heads)\n",
        "        self.masked_multi_head_cross_attention = MultiHeadSelfAttention(d_model=d_model,p_drop=p_drop,num_heads=num_heads)\n",
        "        self.feedforward = FeedForward(d_model=d_model,p_drop=p_drop,d_ff=d_ff)\n",
        "\n",
        "    def forward(self,outputs:torch.Tensor,encoded_sequence:torch.Tensor,self_attention_mask:torch.Tensor=None,cross_attention_mask:torch.Tensor=None) -> torch.Tensor:\n",
        "        output_splits = torch.split(outputs,self.head_dim,dim=2)\n",
        "        masked_output = self.masked_multi_head_self_attention(outputs,Q=output_splits,K=output_splits,V=output_splits,mask=self_attention_mask)\n",
        "\n",
        "        masked_output_splits = torch.split(masked_output,self.head_dim,dim=2)\n",
        "        encoded_sequence_splits = torch.split(encoded_sequence,self.head_dim,dim=2)\n",
        "        mhsa_output = self.masked_multi_head_cross_attention(masked_output,Q=masked_output_splits,K=encoded_sequence_splits,V=encoded_sequence_splits,mask=cross_attention_mask)\n",
        "        return self.feedforward(mhsa_output)\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, number_of_decoder_blocks:int, **kwargs) -> None:\n",
        "        super().__init__()\n",
        "        self.decoder_layers = nn.ModuleList([DecoderLayer(**kwargs) for n in range(number_of_decoder_blocks)])\n",
        "\n",
        "    def forward(self,outputs:torch.Tensor,encoded_sequence:torch.Tensor,self_attention_mask:torch.Tensor=None,cross_attention_mask:torch.Tensor=None) -> torch.Tensor:\n",
        "        for decoder_layer in self.decoder_layers:\n",
        "            outputs = decoder_layer(outputs,encoded_sequence,self_attention_mask,cross_attention_mask)\n",
        "        return outputs\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "4cxBEMG-U7T1"
      },
      "outputs": [],
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(self,\n",
        "                 eng_vocab_size:int,\n",
        "                 swa_vocab_size:int,\n",
        "                 batch_size:int,\n",
        "                 context_size:int,\n",
        "                 d_model:int,\n",
        "                 d_ff:int,\n",
        "                 num_heads:int,\n",
        "                 number_of_encoder_blocks:int,\n",
        "                 number_of_decoder_blocks:int,\n",
        "                 p_drop:float):\n",
        "\n",
        "        super().__init__()\n",
        "        self.context_size = context_size\n",
        "\n",
        "        self.encoder_embedding = EmeddingsLayer(d_model=d_model,vocab_size=eng_vocab_size)\n",
        "        self.decoder_embedding = EmeddingsLayer(d_model=d_model,vocab_size=swa_vocab_size)\n",
        "        self.positional_encoding = PositionalEncoding(d_model=d_model,context_size=context_size)\n",
        "        self.dropout = nn.Dropout(p=p_drop)\n",
        "        self.encoder = Encoder(\n",
        "                            batch_size=batch_size,\n",
        "                            context_size=context_size,\n",
        "                            d_model=d_model,\n",
        "                            d_ff=d_ff,\n",
        "                            num_heads=num_heads,\n",
        "                            number_of_encoder_blocks=number_of_encoder_blocks,\n",
        "                            p_drop=p_drop)\n",
        "\n",
        "        self.decoder = Decoder(\n",
        "                            batch_size=batch_size,\n",
        "                            context_size=context_size,\n",
        "                            d_model=d_model,\n",
        "                            p_drop=p_drop,\n",
        "                            d_ff=d_ff,\n",
        "                            num_heads=num_heads,\n",
        "                            number_of_decoder_blocks=number_of_decoder_blocks)\n",
        "\n",
        "        self.linear = nn.Linear(in_features=d_model,out_features=swa_vocab_size)\n",
        "\n",
        "\n",
        "    def forward(self,X:torch.Tensor,y:torch.Tensor,encoder_mask:torch.Tensor,decoder_self_attention_mask:torch.Tensor,decoder_cross_attention_mask:torch.Tensor) -> torch.Tensor:\n",
        "        pos_encoding = self.positional_encoding().to(device) #\n",
        "        # encode\n",
        "        input_embeddings = self.encoder_embedding(X).to(device)\n",
        "        inputs = self.dropout(input_embeddings+pos_encoding) # B*T*C\n",
        "        encoded_sequence = self.encoder(inputs,encoder_mask)\n",
        "        # decode\n",
        "        output_embedding = self.decoder_embedding(y)\n",
        "        outputs = self.dropout(output_embedding+pos_encoding) # B*T*C\n",
        "        decoder_output = self.decoder(outputs,encoded_sequence,self_attention_mask=decoder_self_attention_mask,cross_attention_mask=decoder_cross_attention_mask)\n",
        "        # linear\n",
        "        output_logits = self.linear(decoder_output)\n",
        "        # output_probs = torch.softmax(output_logits,dim=-1)\n",
        "\n",
        "        return output_logits\n",
        "\n",
        "\n",
        "training_dataset = TranslationDataset(swahili_sentences=swahili_sentences_tokenized_train,english_sentences=english_sentences_tokenized_train,transforms=transforms.ToTensor())\n",
        "testing_dataset = TranslationDataset(swahili_sentences=swahili_sentences_tokenized_test,english_sentences=english_sentences_tokenized_test,transforms=transforms.ToTensor())\n",
        "training_dataloader = DataLoader(training_dataset,batch_size=100,shuffle=True)\n",
        "testing_dataloader = DataLoader(testing_dataset,batch_size=100,shuffle=False)\n",
        "\n",
        "eng_sentence,encoder_mask,swa_sentence,decoder_self_attention_mask,decoder_cross_attention_mask = next(iter(training_dataloader))\n",
        "# print(eng_sentence.shape,swa_sentence.shape)\n",
        "# print(eng_sentence[0])\n",
        "\n",
        "config = {\n",
        "    \"eng_vocab_size\":eng_vocab_size,\n",
        "    \"swa_vocab_size\":swa_vocab_size,\n",
        "    \"batch_size\":20,\n",
        "    \"context_size\":260,\n",
        "    \"d_model\":512,\n",
        "    \"num_heads\":8,\n",
        "    \"d_ff\":2048,\n",
        "    \"number_of_encoder_blocks\": 6,\n",
        "    \"number_of_decoder_blocks\": 6,\n",
        "    \"p_drop\":0.1\n",
        "}\n",
        "\n",
        "model = Transformer(**config).to(device)\n",
        "# model.load_state_dict(torch.load(pathlib.Path(\"models/translator.pt\")))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "UvQDuASQVbKI",
        "outputId": "59454dd6-3077-4855-c353-7f2ec37c817a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0\n",
            "Iteration: 0 Loss: 4.752274036407471\n",
            "English: I don't have enough RAM.********************************************************************************************************************************************************************************************************************************************\n",
            "Swahili Translation: <Sina RAM za kutosha.>**********************************************************************************************************************************************************************************************************************************************\n",
            "Swahili Prediction: ———nr;N<6r<rh—hx”o\"h”xv​———r—————E—pP———————EEE——p”—”p——————————p—————w———————p​————————————<p————​v————————​——p—E————E​———————6————————​————————————p————————​————————————————​E——————————————E—E—Pp​————————————————————E———————————E————<—p—————————<—​——————​———\n",
            "\n",
            "Test English: My airport shuttle bus leaves at six o'clock.***********************************************************************************************************************************************************************************************************************\n",
            "Test Swahili Prediction: <uasi nannu kutoka uwannani wa nuene ninaonuoka saa kumi na mniniu\n",
            "Testing Loss: 1.2924045324325562\n",
            "\n",
            "Test English: There are lots of restaurants and shops within walking distance.****************************************************************************************************************************************************************************************************\n",
            "Test Swahili Prediction: <ouna mikahawa na mauuka menni kwa umnani wa kutemneau\n",
            "Testing Loss: 1.2955071926116943\n",
            "\n",
            "Test English: Their sweet melody made young people feel free.*********************************************************************************************************************************************************************************************************************\n",
            "Test Swahili Prediction: <ooimno eao tamu miliwananna ninana wahisi huouu\n",
            "Testing Loss: 1.253602385520935\n",
            "\n",
            "Test English: The alternative possibilities were resistance and flight.***********************************************************************************************************************************************************************************************************\n",
            "Test Swahili Prediction: <uwemekano mnauana unikuwa unineani na kutoookau\n",
            "Testing Loss: 1.2924057245254517\n",
            "\n",
            "Test English: Your political party is completely corrupt.*************************************************************************************************************************************************************************************************************************\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 10%|█         | 1/10 [00:29<04:23, 29.32s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Swahili Prediction: <nhama nhako uha kisiasa ni nisaui kanisau\n",
            "Testing Loss: 1.2805752754211426\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "Epoch 1\n",
            "Iteration: 0 Loss: 1.4511011838912964\n",
            "English: If only I'd sold that property during the economic bubble, I wouldn't have suffered such a big loss.****************************************************************************************************************************************************************\n",
            "Swahili Translation: <Laiti ningekuwa nimeuza mali hiyo wakati uchumi ulipokuwa mzuri, nisingepata hasara kubwa kama hii.>***************************************************************************************************************************************************************\n",
            "Swahili Prediction: <naiti ninnekuwa nimeuma mali hiyo wakati unhumi uninokuwa mmueiu nisinneoata hasaua kunwa kama hiiuoouoouoouououououuuoouoouuuuuuuououooooooooooouoouooouuuuuouuuuouuuoouuuouuoouuoouooouoouuuuoououoooouuuuuuouoouuuuouuououuuuoououoouuouuuuuuouuoouuouoououuoouo\n",
            "\n",
            "Test English: My airport shuttle bus leaves at six o'clock.***********************************************************************************************************************************************************************************************************************\n",
            "Test Swahili Prediction: <<asi langu kutoka uwanjani wa ndege linaondoka saa kumi na mbili.\n",
            "Testing Loss: 0.30881601572036743\n",
            "\n",
            "Test English: There are lots of restaurants and shops within walking distance.****************************************************************************************************************************************************************************************************\n",
            "Test Swahili Prediction: <<una mikahawa na maduka mengi kwa umbali wa kutembea.\n",
            "Testing Loss: 0.32219794392585754\n",
            "\n",
            "Test English: Their sweet melody made young people feel free.*********************************************************************************************************************************************************************************************************************\n",
            "Test Swahili Prediction: <<yimbo zao tamu ziliwafanya eijana wahisi huru.\n",
            "Testing Loss: 0.3029070794582367\n",
            "\n",
            "Test English: The alternative possibilities were resistance and flight.***********************************************************************************************************************************************************************************************************\n",
            "Test Swahili Prediction: <<wezekano mbadala ulikuwa upinzani na kutoroka.\n",
            "Testing Loss: 0.3232126533985138\n",
            "\n",
            "Test English: Your political party is completely corrupt.*************************************************************************************************************************************************************************************************************************\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 20%|██        | 2/10 [00:58<03:54, 29.31s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Swahili Prediction: <<hama  hako  ha kisiasa ni fisadi kabisa.\n",
            "Testing Loss: 0.31992509961128235\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "Epoch 2\n",
            "Iteration: 0 Loss: 0.40784838795661926\n",
            "English: There is an important alliance between these two countries.*********************************************************************************************************************************************************************************************************\n",
            "Swahili Translation: <Kuna muungano muhimu kati ya nchi hizi mbili.>*********************************************************************************************************************************************************************************************************************\n",
            "Swahili Prediction: <<una muungano muhimu kati ya nchi hizi mbili.\n",
            "\n",
            "Test English: My airport shuttle bus leaves at six o'clock.***********************************************************************************************************************************************************************************************************************\n",
            "Test Swahili Prediction: <<asi langu kutoka uwanjani wa ndege linaondoka saa kumi na mbili.\n",
            "Testing Loss: 0.15190517902374268\n",
            "\n",
            "Test English: There are lots of restaurants and shops within walking distance.****************************************************************************************************************************************************************************************************\n",
            "Test Swahili Prediction: <<una mikahawa na maduka mengi kwa umbali wa kutembea.\n",
            "Testing Loss: 0.16919571161270142\n",
            "\n",
            "Test English: Their sweet melody made young people feel free.*********************************************************************************************************************************************************************************************************************\n",
            "Test Swahili Prediction: <Nyimbo zao tamu ziliwafanya oijana wahisi huru.\n",
            "Testing Loss: 0.1467333287000656\n",
            "\n",
            "Test English: The alternative possibilities were resistance and flight.***********************************************************************************************************************************************************************************************************\n",
            "Test Swahili Prediction: <<wezekano mbadala ulikuwa upinzani na kutoroka.\n",
            "Testing Loss: 0.16739439964294434\n",
            "\n",
            "Test English: Your political party is completely corrupt.*************************************************************************************************************************************************************************************************************************\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 30%|███       | 3/10 [01:27<03:25, 29.30s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Swahili Prediction: <<hama chako cha kisiasa ni fisadi kabisa.\n",
            "Testing Loss: 0.16619783639907837\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "Epoch 3\n",
            "Iteration: 0 Loss: 0.19036589562892914\n",
            "English: I know Jacob doesn't know why Susie is doing that.******************************************************************************************************************************************************************************************************************\n",
            "Swahili Translation: <Najua Jacob hajui kwa nini Susie anafanya hivyo.>******************************************************************************************************************************************************************************************************************\n",
            "Swahili Prediction: <Najua bacob hajui kwa nini \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 30%|███       | 3/10 [01:37<03:48, 32.63s/it]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-87-ccea238362cc>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mvalid_indicies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mswa_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mswa_token_to_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mPADDING_TOKEN\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mvalid_indicies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "EPOCHS = 10\n",
        "loss_fn = nn.CrossEntropyLoss(ignore_index=swa_token_to_index[PADDING_TOKEN],reduction='none').to(device)\n",
        "optimizer = optim.Adam(model.parameters(),lr=1e-5)\n",
        "\n",
        "for epoch in tqdm.tqdm(range(EPOCHS)):\n",
        "    print(f\"Epoch {epoch}\")\n",
        "    # train\n",
        "    model.train()\n",
        "    for batch,(eng_batch,encoder_mask,swa_batch,decoder_self_attention_mask,decoder_cross_attention_mask) in enumerate(training_dataloader):\n",
        "        train_logits = model(eng_batch.to(device),swa_batch.to(device),encoder_mask.to(device),decoder_self_attention_mask.to(device),decoder_cross_attention_mask.to(device))\n",
        "        loss = loss_fn(train_logits.view(-1,swa_vocab_size).to(device),swa_batch.view(-1).to(device))\n",
        "        valid_indicies = torch.where(swa_batch.view(-1) == swa_token_to_index[PADDING_TOKEN], 0, 1)\n",
        "        loss = loss.sum() / valid_indicies.sum()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch % 100 == 0:\n",
        "            print(f\"Iteration: {batch} Loss: {loss.item()}\")\n",
        "            print(f\"English: {''.join([eng_index_to_token[t.item()] for t in eng_batch[0]])}\")\n",
        "            print(f\"Swahili Translation: {''.join([swa_index_to_token[t.item()] for t in swa_batch[0]])}\")\n",
        "            swa_sentence_predicted = torch.softmax(train_logits[0],dim=1).argmax(dim=1)\n",
        "            predicted_sentence = ''\n",
        "            for idx in swa_sentence_predicted:\n",
        "              if idx.item() == swa_token_to_index[END_TOKEN]:\n",
        "                break\n",
        "              elif idx.item() == swa_token_to_index[PADDING_TOKEN]:\n",
        "                predicted_sentence += ''\n",
        "              else:\n",
        "                predicted_sentence += swa_index_to_token[idx.item()]\n",
        "            print(f\"Swahili Prediction: {predicted_sentence}\")\n",
        "            print()\n",
        "\n",
        "    # test\n",
        "    model.eval()\n",
        "    with torch.inference_mode():\n",
        "      for test_batch,(test_eng_batch,test_encoder_mask,test_swa_batch,test_decoder_self_attention_mask,test_decoder_cross_attention_mask) in enumerate(testing_dataloader):\n",
        "          print(f\"Test English: {''.join([eng_index_to_token[t.item()] for t in test_eng_batch[0]])}\")\n",
        "          test_logits = model(test_eng_batch.to(device),test_swa_batch.to(device),test_encoder_mask.to(device),test_decoder_self_attention_mask.to(device),test_decoder_cross_attention_mask.to(device))\n",
        "          swa_sentence_predicted = torch.softmax(test_logits[0],dim=1).argmax(dim=1)\n",
        "          predicted_sentence = ''\n",
        "          for idx in swa_sentence_predicted:\n",
        "            if idx == swa_token_to_index[END_TOKEN]:\n",
        "              break\n",
        "            elif idx == swa_token_to_index[PADDING_TOKEN]:\n",
        "              predicted_sentence += ''\n",
        "            else:\n",
        "              predicted_sentence += swa_index_to_token[idx.item()]\n",
        "          print(f\"Test Swahili Prediction: {predicted_sentence}\")\n",
        "          loss = loss_fn(test_logits.view(-1,swa_vocab_size).to(device),test_swa_batch.view(-1).to(device))\n",
        "          valid_indicies = torch.where(test_swa_batch.view(-1) == swa_token_to_index[PADDING_TOKEN], False, True)\n",
        "          loss = loss.sum() / valid_indicies.sum()\n",
        "          print(f\"Testing Loss: {loss.item()}\")\n",
        "          print()\n",
        "          # break\n",
        "    print(\"------------------------------------------------------------------------\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LfFw9aANjfFv",
        "outputId": "023f8e7c-8182-4017-b372-7b972f408dc9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "120338764\n",
            "model size: 114.764MB\n",
            "mkdir: cannot create directory ‘models’: File exists\n"
          ]
        }
      ],
      "source": [
        "param_size = 0\n",
        "for param in model.parameters():\n",
        "    param_size += param.nelement() * param.element_size()\n",
        "buffer_size = 0\n",
        "for buffer in model.buffers():\n",
        "    buffer_size += buffer.nelement() * buffer.element_size()\n",
        "print((param_size + buffer_size))\n",
        "size_all_mb = (param_size + buffer_size) / 1024**2\n",
        "print('model size: {:.3f}MB'.format(size_all_mb))\n",
        "!mkdir models\n",
        "MODEL_PATH = pathlib.Path(\"models/translator.pt\")\n",
        "\n",
        "torch.save(model.state_dict(),MODEL_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "y3q3DBjGwQtD"
      },
      "outputs": [],
      "source": [
        "def tokenize(eng_sentence,swa_sentence):\n",
        "  english_sentence_tokenized = [[eng_token_to_index[t] for t in s] for s in eng_sentence]\n",
        "  swahili_sentence_tokenized = [[swa_token_to_index[t] for t in s] for s in swa_sentence]\n",
        "  # print(english_sentence_tokenized)\n",
        "  # print(swahili_sentence_tokenized)\n",
        "  eval_dataset = TranslationDataset(swahili_sentences=swahili_sentence_tokenized,english_sentences=english_sentence_tokenized,transforms=transforms.ToTensor())\n",
        "  eval_dataloader = DataLoader(eval_dataset,batch_size=1,shuffle=False)\n",
        "  return next(iter(eval_dataloader))\n",
        "\n",
        "\n",
        "def translate(eng_sentence):\n",
        "  # model = Transformer(**config).to(device)\n",
        "  # model.load_state_dict(torch.load(pathlib.Path(\"models/translator.pt\")))\n",
        "  model.eval()\n",
        "  with torch.inference_mode():\n",
        "    eng_sentence = (eng_sentence,)\n",
        "    swa_sentence = (START_TOKEN,)\n",
        "\n",
        "    for word_counter in range(260):\n",
        "      eng_batch,encoder_mask,swa_batch,decoder_self_attention_mask,decoder_cross_attention_mask = tokenize(eng_sentence,swa_sentence)\n",
        "      # print(encoder_mask)\n",
        "      predictions = model(eng_batch.to(device),swa_batch.to(device),encoder_mask.to(device),decoder_self_attention_mask.to(device),decoder_cross_attention_mask.to(device))\n",
        "      next_token_prob_distribution = torch.softmax(predictions[0],dim=1).argmax(dim=1)\n",
        "      # print(next_token_prob_distribution)\n",
        "      next_token_index = next_token_prob_distribution[word_counter].item()\n",
        "      next_token = swa_index_to_token[next_token_index]\n",
        "      swa_sentence = (swa_sentence[0] + next_token, )\n",
        "      # print(next_token)\n",
        "      if next_token == END_TOKEN:\n",
        "        break\n",
        "      # break\n",
        "    return swa_sentence[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "4qeafAP702vP",
        "outputId": "c73d074e-b0aa-487c-8a18-7cf3ca6f8fbc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'00000000U000U0UUU00UUUUUUUUU0UUUUUUUUUUUUUUUUUUUUoUUUUUUUUoUUUUUUUUUoUoUUoUUUoUUUUoooUUoooUoUUUUUooooooUUUoooooUUUooUoUoooUooUoooooooooooooooooooooUoooooooooooooooooooooooooooooo!!ooo!oooo!ooooo!!!!o!!!!!!!o!!!!!!!!!o!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!'"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "translation = translate(\"I am a man\")\n",
        "translation"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
